{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0tjLd13gSOzH"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook is for the major project submission for COMP7220/8220, on the [image/language] dataset and task.  It contains the following sections:\n",
    "\n",
    "*   a description of the selected conventional ML model;\n",
    "*   some notes about the choices made in building the conventional ML model;\n",
    "*   a description of the selected deep learning model;\n",
    "*   some notes about the choices made in building the deep model; and\n",
    "*   a discussion of the performance of the two models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rZenD0ZqVAt9"
   },
   "source": [
    "# Conventional ML Model\n",
    "\n",
    "The final model that produced the best-performing predictions for the Kaggle submission (accuracy x%) was an SVM with a polynomial kernel.  The features were ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zJzTLEezSL_J"
   },
   "outputs": [],
   "source": [
    "# some initialisation code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qtFYH5HGVPLc"
   },
   "source": [
    "The code below handles feature extraction by first preprocessing the text, and then ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FJHWLg8BVYo7"
   },
   "outputs": [],
   "source": [
    "# preprocessing + feature extraction code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gF6wCdyrVX4-"
   },
   "source": [
    "The model is defined ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uLZku14oVhPQ"
   },
   "outputs": [],
   "source": [
    "# model definition code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HEGAmgJbVuSR"
   },
   "source": [
    "# Notes on the Conventional ML Model\n",
    "\n",
    "For the final model, hyperparameters were chosen by ...\n",
    "\n",
    "In addition to the final model, I also tried a logistic regression model, ...  This performed fairly poorly (accuracy y%) ...  This may have been because ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "exJ0WB6EWipX"
   },
   "source": [
    "# Deep Learning Model\n",
    "\n",
    "The final model that produced the best-performing predictions for the Kaggle submission (accuracy (x+5)%) was a fully connected dense model with NN layers.  The input was the raw data that had been preprocessed by ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8OoUKNz3Wv9g"
   },
   "source": [
    "[Following this, code and comments as above.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EcDCI2dIW3ir"
   },
   "source": [
    "# Notes on the Deep Learning Model\n",
    "\n",
    "For the final model, hyperparameters were chosen by ...\n",
    "\n",
    "In addition to the final model, I also tried a CNN with two conv layers and ...  This performed almost as well as the final model (accuracy (x-3)%) ...  This gap in performance may have been because ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O1ngpqdsXg2m"
   },
   "source": [
    "# Discussion of Model Performance and Implementation\n",
    "\n",
    "Comparing my final conventional ML and deep learning models, the deep learning one performed better by 5% on the public test set.  The deep learning model ranked #12 out of N submissions on the public test set, with the top-performing system having z% accuracy, and a majority class baseline having z'% accuracy ...\n",
    "\n",
    "[E.g. discussion about what performance on validation set versus public test set might say about your models or about the dataset.]\n",
    "\n",
    "[E.g. discussion about what performance on private test set versus public test set might say about your models or about the dataset.]\n",
    "\n",
    "[E.g. discussion about what inspecting the data might say about your models or about the dataset.]\n",
    "\n",
    "[E.g. reflection on resource required for models or other implementation issues.]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN3CmX3oULHqPfTSyXSwAHg",
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
